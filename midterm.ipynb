{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374230ac-73fe-4835-b15a-a71f602a2fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - nvidia\n",
      " - pytorch\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 24.7.1\n",
      "    latest version: 24.9.2\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - joblib\n",
      "    - lightgbm\n",
      "    - nltk\n",
      "    - textblob\n",
      "    - xgboost\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    libboost-1.84.0            |       hb8260a3_6         2.7 MB  conda-forge\n",
      "    liblightgbm-4.5.0          |   cpu_h155599f_3         2.8 MB  conda-forge\n",
      "    lightgbm-4.5.0             |         cpu_py_3          81 KB  conda-forge\n",
      "    ocl-icd-2.3.2              |       hd590300_1         133 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         5.8 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  libboost           conda-forge/linux-64::libboost-1.84.0-hb8260a3_6 \n",
      "  liblightgbm        conda-forge/linux-64::liblightgbm-4.5.0-cpu_h155599f_3 \n",
      "  lightgbm           conda-forge/noarch::lightgbm-4.5.0-cpu_py_3 \n",
      "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.2-hd590300_1 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "liblightgbm-4.5.0    | 2.8 MB    |                                       |   0% \n",
      "libboost-1.84.0      | 2.7 MB    |                                       |   0% \u001b[A\n",
      "\n",
      "ocl-icd-2.3.2        | 133 KB    |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "liblightgbm-4.5.0    | 2.8 MB    | ##############8                       |  40% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "lightgbm-4.5.0       | 81 KB     | #######3                              |  20% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "ocl-icd-2.3.2        | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "ocl-icd-2.3.2        | 133 KB    | ##################################### | 100% \u001b[A\u001b[A\n",
      "libboost-1.84.0      | 2.7 MB    | 2                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "lightgbm-4.5.0       | 81 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install joblib nltk xgboost textblob lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac753cc-9cea-422f-b3bf-a5d169b034d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import warnings\n",
    "import multiprocessing\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import lightgbm as lgb  # LightGBM for model training\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e20a2940-a565-41a6-8cc0-3185f0b944c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Download necessary NLTK data files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Number of CPU cores\n",
    "num_cores = multiprocessing.cpu_count() - 4\n",
    "print(f\"Number of CPU cores: {num_cores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5c40d92-9cf7-4bd0-a1b1-9c07cdd013ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "print(\"Loading data...\")\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_ids = pd.read_csv('test.csv')['Id']\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb454d9d-6d0a-4ce9-bb80-933fcacef3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 2. Data Preprocessing\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Split the data\n",
    "test_data = train_df[train_df['Id'].isin(test_ids)].copy()\n",
    "train_data = train_df[~train_df['Id'].isin(test_ids)].copy()\n",
    "\n",
    "# Ensure that the 'Score' column is missing in test_data and present in train_data\n",
    "train_data = train_data[train_data['Score'].notnull()]\n",
    "test_data = test_data[test_data['Score'].isnull()]\n",
    "\n",
    "# Fill missing values in 'Summary' and 'Text' with empty strings\n",
    "train_data['Summary'] = train_data['Summary'].fillna('')\n",
    "train_data['Text'] = train_data['Text'].fillna('')\n",
    "test_data['Summary'] = test_data['Summary'].fillna('')\n",
    "test_data['Text'] = test_data['Text'].fillna('')\n",
    "\n",
    "# Combine 'Summary' and 'Text' into a single field 'FullText'\n",
    "train_data['FullText'] = train_data['Summary'] + ' ' + train_data['Text']\n",
    "test_data['FullText'] = test_data['Summary'] + ' ' + test_data['Text']\n",
    "\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645b47e0-eee0-4747-880a-9fab66f580cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning text...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 3. Feature Engineering\n",
    "\n",
    "# 3.1 Text Cleaning Function\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stopwords\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "    # Lemmatize words\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # Join words back into one string\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply text cleaning in parallel\n",
    "print(\"Cleaning text...\")\n",
    "\n",
    "def parallel_apply(df, func):\n",
    "    df_split = np.array_split(df, num_cores)\n",
    "    pool = multiprocessing.Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def clean_text_df(df):\n",
    "    df['CleanText'] = df['FullText'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "train_data = parallel_apply(train_data, clean_text_df)\n",
    "test_data = parallel_apply(test_data, clean_text_df)\n",
    "\n",
    "# Check for empty 'CleanText' entries\n",
    "train_data['CleanText'].replace('', 'empty', inplace=True)\n",
    "test_data['CleanText'].replace('', 'empty', inplace=True)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66abb11d-7f00-4a85-81f2-5e5fdd246252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TF-IDF vectorizer on training data...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 4. Feature Engineering\n",
    "\n",
    "# 4.1 TF-IDF Vectorization with Bigrams and Trigrams\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=100000, ngram_range=(1,3), min_df=5, max_df=0.9, verbose=1 )\n",
    "\n",
    "print(\"Fitting TF-IDF vectorizer on training data...\")\n",
    "tfidf.fit(train_data['CleanText'])\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d325c9c7-dc2d-4e67-bbfa-f9c8c1439fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming training data with TF-IDF vectorizer in parallel...\n",
      "Transforming test data with TF-IDF vectorizer in parallel...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Function to transform a chunk of data\n",
    "def transform_chunk(chunk):\n",
    "    return tfidf.transform(chunk)\n",
    "\n",
    "# Transform training data in parallel\n",
    "print(\"Transforming training data with TF-IDF vectorizer in parallel...\")\n",
    "train_chunks = np.array_split(train_data['CleanText'], num_cores)\n",
    "X_train_tfidf_chunks = Parallel(n_jobs=num_cores)(\n",
    "    delayed(transform_chunk)(chunk) for chunk in train_chunks\n",
    ")\n",
    "X_train_tfidf = vstack(X_train_tfidf_chunks)\n",
    "\n",
    "# Transform test data in parallel\n",
    "print(\"Transforming test data with TF-IDF vectorizer in parallel...\")\n",
    "test_chunks = np.array_split(test_data['CleanText'], num_cores)\n",
    "X_test_tfidf_chunks = Parallel(n_jobs=num_cores)(\n",
    "    delayed(transform_chunk)(chunk) for chunk in test_chunks\n",
    ")\n",
    "X_test_tfidf = vstack(X_test_tfidf_chunks)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de5cab01-4a11-4165-a78f-61febf34fb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing additional features...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 4.2 Additional Features (HelpfulnessRatio, Date Features, etc.)\n",
    "print(\"Computing additional features...\")\n",
    "\n",
    "def compute_features(df):\n",
    "    # Helpfulness Ratio\n",
    "    df['HelpfulnessRatio'] = np.where(df['HelpfulnessDenominator'] == 0, 0,\n",
    "                                      df['HelpfulnessNumerator'] / df['HelpfulnessDenominator'])\n",
    "    # Review Time Features\n",
    "    df['ReviewTime'] = pd.to_datetime(df['Time'], unit='s')\n",
    "    df['ReviewYear'] = df['ReviewTime'].dt.year\n",
    "    df['ReviewMonth'] = df['ReviewTime'].dt.month\n",
    "    df['ReviewDayOfWeek'] = df['ReviewTime'].dt.dayofweek\n",
    "    # Review Length\n",
    "    df['ReviewLength'] = df['CleanText'].apply(lambda x: len(x.split()))\n",
    "    return df\n",
    "\n",
    "train_data = parallel_apply(train_data, compute_features)\n",
    "test_data = parallel_apply(test_data, compute_features)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b4aa5c6-e2b9-4337-a8d8-0713496115c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding 'UserId' and 'ProductId'...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Encode 'UserId' and 'ProductId' using frequency encoding\n",
    "print(\"Encoding 'UserId' and 'ProductId'...\")\n",
    "\n",
    "def frequency_encoding(column, df_train, df_test):\n",
    "    freq_enc = df_train[column].value_counts().to_dict()\n",
    "    df_train[column + '_FreqEnc'] = df_train[column].map(freq_enc)\n",
    "    df_test[column + '_FreqEnc'] = df_test[column].map(freq_enc)\n",
    "    # Fill NaNs in test data with minimum frequency\n",
    "    min_freq = min(freq_enc.values())\n",
    "    df_test[column + '_FreqEnc'] = df_test[column + '_FreqEnc'].fillna(min_freq)\n",
    "    return df_train, df_test\n",
    "\n",
    "train_data, test_data = frequency_encoding('UserId', train_data, test_data)\n",
    "train_data, test_data = frequency_encoding('ProductId', train_data, test_data)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019183c6-3d3e-4dfc-b550-cb6000221f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing sentiment analysis...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Sentiment Analysis using TextBlob\n",
    "print(\"Performing sentiment analysis...\")\n",
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis(df):\n",
    "    df['Sentiment'] = df['CleanText'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "    return df\n",
    "\n",
    "train_data = parallel_apply(train_data, sentiment_analysis)\n",
    "test_data = parallel_apply(test_data, sentiment_analysis)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a49cffc-476c-40e6-b507-b68b896cc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing feature sets...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 4.3 Finalize Feature Sets\n",
    "print(\"Finalizing feature sets...\")\n",
    "numerical_features = ['HelpfulnessRatio', 'ReviewYear', 'ReviewMonth', 'ReviewDayOfWeek',\n",
    "                      'ReviewLength', 'UserId_FreqEnc', 'ProductId_FreqEnc', 'Sentiment']\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57a1f9d6-edcf-4f6a-8914-5966e6d0dd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "train_num = scaler.fit_transform(train_data[numerical_features])\n",
    "test_num = scaler.transform(test_data[numerical_features])\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6444d8b-be75-41c0-a98d-4c3e842f0a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing dimensionality...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Reduce dimensionality with TruncatedSVD\n",
    "print(\"Reducing dimensionality...\")\n",
    "svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "X_train_svd = svd.fit_transform(X_train_tfidf)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "741b5a00-e6b4-400e-8ce4-2e20f92e2792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining all features...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Combine all features\n",
    "print(\"Combining all features...\")\n",
    "X_train = np.hstack([train_num, X_train_svd])\n",
    "X_test = np.hstack([test_num, X_test_svd])\n",
    "\n",
    "y_train = train_data['Score'].astype(int)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff22eeb8-2feb-4b13-a618-f0a3893346e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing LightGBM dataset...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 5. Model Training\n",
    "\n",
    "# 5.1 Prepare LightGBM Dataset\n",
    "print(\"Preparing LightGBM dataset...\")\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e77d48b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "542f5eab-47f6-4baa-87d1-d5b27bb2b6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling data for hyperparameter tuning...\n",
      "Initializing RandomizedSearchCV...\n",
      "Fitting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.090457 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52296\n",
      "[LightGBM] [Info] Number of data points in the train set: 148534, number of used features: 208\n",
      "[LightGBM] [Info] Start training from score -2.790454\n",
      "[LightGBM] [Info] Start training from score -2.807151\n",
      "[LightGBM] [Info] Start training from score -2.132461\n",
      "[LightGBM] [Info] Start training from score -1.488582\n",
      "[LightGBM] [Info] Start training from score -0.627374\n",
      "Best parameters found:\n",
      "{'num_leaves': 63, 'n_estimators': 500, 'learning_rate': 0.05}\n",
      "Training final model on full dataset...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52299\n",
      "[LightGBM] [Info] Number of data points in the train set: 1485341, number of used features: 208\n",
      "[LightGBM] [Info] Start training from score -2.790454\n",
      "[LightGBM] [Info] Start training from score -2.807174\n",
      "[LightGBM] [Info] Start training from score -2.132450\n",
      "[LightGBM] [Info] Start training from score -1.488589\n",
      "[LightGBM] [Info] Start training from score -0.627371\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52295\n",
      "[LightGBM] [Info] Number of data points in the train set: 74267, number of used features: 208\n",
      "[LightGBM] [Info] Start training from score -2.790563\n",
      "[LightGBM] [Info] Start training from score -2.807151\n",
      "[LightGBM] [Info] Start training from score -2.132461\n",
      "[LightGBM] [Info] Start training from score -1.488552\n",
      "[LightGBM] [Info] Start training from score -0.627374\n",
      "[CV 2/2] END learning_rate=0.05, n_estimators=500, num_leaves=63;, score=0.622 total time= 4.2min\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 52295\n",
      "[LightGBM] [Info] Number of data points in the train set: 74267, number of used features: 208\n",
      "[LightGBM] [Info] Start training from score -2.790344\n",
      "[LightGBM] [Info] Start training from score -2.807151\n",
      "[LightGBM] [Info] Start training from score -2.132461\n",
      "[LightGBM] [Info] Start training from score -1.488612\n",
      "[LightGBM] [Info] Start training from score -0.627374\n",
      "[CV 1/2] END learning_rate=0.05, n_estimators=500, num_leaves=63;, score=0.624 total time=  52.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.05, n_estimators=500, n_jobs=-1, num_leaves=63,\n",
       "               objective=&#x27;multiclass&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(learning_rate=0.05, n_estimators=500, n_jobs=-1, num_leaves=63,\n",
       "               objective=&#x27;multiclass&#x27;, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.05, n_estimators=500, n_jobs=-1, num_leaves=63,\n",
       "               objective='multiclass', random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Sample a subset of the data for hyperparameter tuning\n",
    "print(\"Sampling data for hyperparameter tuning...\")\n",
    "X_sample, _, y_sample, _ = train_test_split(X_train, y_train, test_size=0.9, random_state=42, stratify=y_train)\n",
    "\n",
    "# Simplify parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [31, 63],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [500],\n",
    "}\n",
    "\n",
    "lgb_estimator = lgb.LGBMClassifier(objective='multiclass', n_jobs=-1, random_state=42)\n",
    "\n",
    "# Use RandomizedSearchCV for hyperparameter tuning\n",
    "print(\"Initializing RandomizedSearchCV...\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=lgb_estimator,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=2,  # Reduced due to simplified grid\n",
    "    scoring='accuracy',\n",
    "    cv=2,  # Reduced folds\n",
    "    verbose=3,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(\"Fitting RandomizedSearchCV...\")\n",
    "random_search.fit(X_sample, y_sample)\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Train the final model on the full dataset\n",
    "print(\"Training final model on full dataset...\")\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "final_model = lgb.LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_metric='multi_logloss',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c951a5-5ae0-44f0-be4d-98a557c3f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on test data...\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# 6. Prediction\n",
    "print(\"Predicting on test data...\")\n",
    "y_pred = final_model.predict(X_test)\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15c038f9-45dc-4270-99f6-d05515611a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing submission file...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# 7. Prepare Submission\n",
    "print(\"Preparing submission file...\")\n",
    "submission = pd.DataFrame({'Id': test_data['Id'], 'Score': y_pred.astype(float)})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de4dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
